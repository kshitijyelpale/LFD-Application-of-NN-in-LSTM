{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bi-Directional LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmtnPZYdGDZ1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "80e5395d-9e06-4b7e-eb13-9ebb3dfec1a1"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "max_features = 20000  # Only consider the top 20k words\n",
        "maxlen = 200  # Only consider the first 200 words of each movie review\n",
        "\n",
        "# Input for variable-length sequences of integers\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
        "\n",
        "# Embed each integer in a 128-dimensional vector\n",
        "x = layers.Embedding(max_features, 128)(inputs)\n",
        "\n",
        "# Add 2 bidirectional LSTMs\n",
        "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
        "\n",
        "# Add a classifier\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.summary()\n",
        "\n",
        "#Load the IMDB movie review sentiment data\n",
        "(x_train, y_train), (x_val, y_val) = keras.datasets.imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), \"Training sequences\")\n",
        "print(len(x_val), \"Validation sequences\")\n",
        "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_val = keras.preprocessing.sequence.pad_sequences(x_val, maxlen=maxlen)\n",
        "\n",
        "#Train and evaluate the model\n",
        "model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=2, validation_data=(x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, None)]            0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, None, 128)         2560000   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, None, 128)         98816     \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 2,757,761\n",
            "Trainable params: 2,757,761\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "25000 Training sequences\n",
            "25000 Validation sequences\n",
            "Epoch 1/2\n",
            "782/782 [==============================] - 451s 576ms/step - loss: 0.5371 - accuracy: 0.7326 - val_loss: 0.4382 - val_accuracy: 0.8034\n",
            "Epoch 2/2\n",
            "782/782 [==============================] - 452s 578ms/step - loss: 0.3540 - accuracy: 0.8542 - val_loss: 0.3604 - val_accuracy: 0.8423\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f02f74936a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5Kj8VBPGMwS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "35185cc6-b2b9-40ff-fbb1-6e25c60d03be"
      },
      "source": [
        "#New Predictions\n",
        "from keras.datasets import imdb\n",
        "\n",
        "new_review = [\"\"\"I absolutely adored this movie. For me, the best reason to see it is how stark a contrast it is from legal dramas like \"Boston Legal\" or \"Ally McBeal\" or even \"LA Law.\" This is REALITY. The law is not BS, won in some closing argument or through some ridiculous defense you pull out of your butt, like the \"Chewbacca defense\" on South Park.) This is a real travesty of justice, the legal system gone horribly wrong, and the work by GOOD lawyers - not the shyster stereotype, who use all of their skills to right it. It will do more for restoring your faith in humanity than any Frank Capra movie or TO KILL A MOCKINGBIRD. And most importantly, I wept. During the film, during the featurette included at the end of the DVD - it's amazing. Wonderful film; wonderfully made. Thank God the filmmakers made it.\"\"\"]\n",
        "word_indices = imdb.get_word_index()\n",
        "reviews = []\n",
        "for doc in new_review:\n",
        "  review = []\n",
        "  for word in doc:\n",
        "    if word not in word_indices:\n",
        "      review.append(2)\n",
        "    else:\n",
        "      review.append(word_indices[word] + 3)\n",
        "  review.sort(reverse=True)\n",
        "  reviews.append(review)\n",
        "x_test = keras.preprocessing.sequence.pad_sequences(reviews, truncating = 'post', padding = 'post', maxlen = maxlen)\n",
        "print(model.predict(x_test))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.98627913]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}